{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file and skip the first row\n",
    "df = pd.read_csv('MFI_participant EXCEL.csv', skiprows=1)\n",
    "\n",
    "# Infer the data types\n",
    "df.infer_objects()\n",
    "\n",
    "# Print the data types of each column\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Muscle fat infiltration | Instance 2'].isna().sum()# 450072 + 27922"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of empty cells in each row\n",
    "empty_counts = df.isna().sum(axis=1)\n",
    "\n",
    "# Calculate the fraction of empty cells in each row\n",
    "empty_fractions = empty_counts / len(df.columns)\n",
    "\n",
    "# Find the rows where 90% or more of the cells are empty - note only 4 columns are mandatory around 2.4% of 165 data points\n",
    "rows_with_mostly_empty_cells = df[empty_fractions >= 0.9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rows_with_mostly_empty_cells) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rows_with_mostly_empty_cells) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows where 97% or more of the cells are empty\n",
    "data = df.drop(index=rows_with_mostly_empty_cells.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['Muscle fat infiltration | Instance 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Muscle fat infiltration | Instance 2'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['Anterior thigh muscle fat infiltration (MFI) (left) | Instance 2',\n",
    " 'Anterior thigh muscle fat infiltration (MFI) (right) | Instance 2',\n",
    " 'Muscle fat infiltration | Instance 2',\n",
    " 'Posterior thigh muscle fat infiltration (MFI) (left) | Instance 2',\n",
    " 'Posterior thigh muscle fat infiltration (MFI) (right) | Instance 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_columns = list(set(all_columns) - set(target_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dexa_features =[#'Participant ID','Age at recruitment',\n",
    "'Head bone area | Instance 2',\n",
    "'Arm BMC (bone mineral content) (left) | Instance 2',\n",
    "'Arm BMC (bone mineral content) (right) | Instance 2',\n",
    "'Arms combined bone area | Instance 2',\n",
    "'Arm BMD (bone mineral density) (left) | Instance 2',\n",
    "'Arm BMD (bone mineral density) (right) | Instance 2',\n",
    "'Arm bone area (left) | Instance 2',\n",
    "'Arm bone area (right) | Instance 2',\n",
    "'Ribs bone area | Instance 2',\n",
    "'Arms BMC (bone mineral content) | Instance 2',\n",
    "'Arms BMD (bone mineral density) | Instance 2',\n",
    "'Spine bone area | Instance 2',\n",
    "'Femur lower neck BMD (bone mineral density) (left) | Instance 2',\n",
    "'Femur lower neck BMD (bone mineral density) (right) | Instance 2',\n",
    "'Trunk bone area | Instance 2',\n",
    "'Pelvis bone area | Instance 2',\n",
    "'Legs combined bone area | Instance 2',\n",
    "'Leg bone area (left) | Instance 2',\n",
    "'Femur neck BMD (bone mineral density) (left) | Instance 2',\n",
    "'Femur neck BMD (bone mineral density) (right) | Instance 2',\n",
    "'Leg bone area (right) | Instance 2',\n",
    "'Femur neck BMC (bone mineral content) (left) | Instance 2',\n",
    "'Femur neck BMC (bone mineral content) (right) | Instance 2',\n",
    "'Femur neck bone area (left) | Instance 2',\n",
    "'Femur neck bone area (right) | Instance 2',\n",
    "'Femur shaft BMC (bone mineral content) (left) | Instance 2',\n",
    "'Femur shaft BMC (bone mineral content) (right) | Instance 2',\n",
    "'Femur shaft bone area (left) | Instance 2',\n",
    "'Femur shaft bone area (right) | Instance 2',\n",
    "'Femur total BMC (bone mineral content) (left) | Instance 2',\n",
    "'Femur total BMC (bone mineral content) (right) | Instance 2',\n",
    "'Femur total area (left) | Instance 2',\n",
    "'Femur total area (right) | Instance 2',\n",
    "'Femur troch BMC (bone mineral content) (left) | Instance 2',\n",
    "'Femur troch BMC (bone mineral content) (right) | Instance 2',\n",
    "'Femur troch bone area (left) | Instance 2',\n",
    "'Femur troch bone area (right) | Instance 2',\n",
    "'Femur wards BMC (bone mineral content) (left) | Instance 2',\n",
    "'Femur wards BMC (bone mineral content) (right) | Instance 2',\n",
    "'Femur wards bone area (left) | Instance 2',\n",
    "'Femur wards bone area (right) | Instance 2',\n",
    "'Femur neck BMD (bone mineral density) T-score (left) | Instance 2',\n",
    "'Femur neck BMD (bone mineral density) T-score (right) | Instance 2',\n",
    "'Femur shaft BMD (bone mineral density) (left) | Instance 2',\n",
    "'Femur shaft BMD (bone mineral density) (right) | Instance 2',\n",
    "'Femur total BMD (bone mineral density) (left) | Instance 2',\n",
    "'Femur total BMD (bone mineral density) (right) | Instance 2',\n",
    "'Femur total BMD (bone mineral density) T-score (left) | Instance 2',\n",
    "'Femur total BMD (bone mineral density) T-score (right) | Instance 2',\n",
    "'Femur troch BMD (bone mineral density) (left) | Instance 2',\n",
    "'Femur troch BMD (bone mineral density) (right) | Instance 2',\n",
    "'Femur troch BMD (bone mineral density) T-score (left) | Instance 2',\n",
    "'Femur troch BMD (bone mineral density) T-score (right) | Instance 2',\n",
    "'L1-L4 area | Instance 2',\n",
    "'L1-L4 average height | Instance 2',\n",
    "'L1-L4 average width | Instance 2',\n",
    "'L1-L4 TBS (trabecular bone score) | Instance 2',\n",
    "'Femur upper neck BMD (bone mineral density) (left) | Instance 2',\n",
    "'Femur upper neck BMD (bone mineral density) (right) | Instance 2',\n",
    "'Femur upper neck BMD (bone mineral density) T-score (left) | Instance 2',\n",
    "'Femur upper neck BMD (bone mineral density) T-score (right) | Instance 2',\n",
    "'Femur wards BMD (bone mineral density) (left) | Instance 2',\n",
    "'Femur wards BMD (bone mineral density) (right) | Instance 2',\n",
    "'Femur wards BMD (bone mineral density) T-score (left) | Instance 2',\n",
    "'Femur wards BMD (bone mineral density) T-score (right) | Instance 2',\n",
    "'Head BMC (bone mineral content) | Instance 2',\n",
    "'Head BMD (bone mineral density) | Instance 2',\n",
    "'L1-L4 BMC (bone mineral content) | Instance 2',\n",
    "'L1-L4 BMD (bone mineral density) | Instance 2',\n",
    "'L1-L4 BMD (bone mineral density) T-score | Instance 2',\n",
    "'Leg BMC (bone mineral content) (left) | Instance 2',\n",
    "'Leg BMC (bone mineral content) (right) | Instance 2',\n",
    "'Leg BMD (bone mineral density) (left) | Instance 2',\n",
    "'Leg BMD (bone mineral density) (right) | Instance 2',\n",
    "'Legs BMC (bone mineral content) | Instance 2',\n",
    "'Legs BMD (bone mineral density) | Instance 2',\n",
    "'Pelvis BMC (bone mineral content) | Instance 2',\n",
    "'Pelvis BMD (bone mineral density) | Instance 2',\n",
    "'Ribs BMC (bone mineral content) | Instance 2',\n",
    "'Ribs BMD (bone mineral density) | Instance 2',\n",
    "'Spine BMC (bone mineral content) | Instance 2',\n",
    "'Spine BMD (bone mineral density) | Instance 2',\n",
    "'Total BMC (bone mineral content) | Instance 2',\n",
    "'Total BMD (bone mineral density) | Instance 2',\n",
    "'Total BMD (bone mineral density) (left) | Instance 2',\n",
    "'Total BMD (bone mineral density) (right) | Instance 2',\n",
    "'Total BMD (bone mineral density) T-score | Instance 2',\n",
    "'Trunk BMC (bone mineral content) | Instance 2',\n",
    "'Trunk BMD (bone mineral density) | Instance 2',\n",
    "'Trunk BMD (bone mineral density) (left) | Instance 2',\n",
    "'Trunk BMD (bone mineral density) (right) | Instance 2',\n",
    "'Android bone mass | Instance 2',\n",
    "'Android fat mass | Instance 2',\n",
    "'Android lean mass | Instance 2',\n",
    "'Android tissue fat percentage | Instance 2',\n",
    "'Android total mass | Instance 2',\n",
    "'Arm fat mass (left) | Instance 2',\n",
    "'Arm fat mass (right) | Instance 2',\n",
    "'Arm lean mass (left) | Instance 2',\n",
    "'Arm lean mass (right) | Instance 2',\n",
    "'Arm tissue fat percentage (left) | Instance 2',\n",
    "'Arm tissue fat percentage (right) | Instance 2',\n",
    "'Arm total mass (left) | Instance 2',\n",
    "'Arm total mass (right) | Instance 2',\n",
    "'Arms fat mass | Instance 2',\n",
    "'Arms lean mass | Instance 2',\n",
    "'Arms tissue fat percentage | Instance 2',\n",
    "'Arms total mass | Instance 2',\n",
    "'Gynoid bone mass | Instance 2',\n",
    "'Gynoid fat mass | Instance 2',\n",
    "'Gynoid lean mass | Instance 2',\n",
    "'Gynoid tissue fat percentage | Instance 2',\n",
    "'Gynoid total mass | Instance 2',\n",
    "'Leg fat mass (left) | Instance 2',\n",
    "'Leg fat mass (right) | Instance 2',\n",
    "'Leg lean mass (left) | Instance 2',\n",
    "'Leg lean mass (right) | Instance 2',\n",
    "'Leg tissue fat percentage (left) | Instance 2',\n",
    "'Leg tissue fat percentage (right) | Instance 2',\n",
    "'Leg total mass (left) | Instance 2',\n",
    "'Leg total mass (right) | Instance 2',\n",
    "'Legs fat mass | Instance 2',\n",
    "'Legs lean mass | Instance 2',\n",
    "'Legs tissue fat percentage | Instance 2',\n",
    "'Total fat mass | Instance 2',\n",
    "'Total fat-free mass | Instance 2',\n",
    "'Total lean mass | Instance 2',\n",
    "'Total tissue fat percentage | Instance 2',\n",
    "'Total tissue mass | Instance 2',\n",
    "'Total mass | Instance 2',\n",
    "'Trunk fat mass | Instance 2',\n",
    "'Trunk lean mass | Instance 2',\n",
    "'Trunk tissue fat percentage | Instance 2',\n",
    "'Trunk total mass | Instance 2',\n",
    "'VAT (visceral adipose tissue) mass | Instance 2',\n",
    "'VAT (visceral adipose tissue) volume | Instance 2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dexa_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[dexa_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = data[target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fraction = train_data.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fraction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=[x/100 for x in range(1, 100, 1)]\n",
    "empty_col_num = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in threshold:\n",
    "    empty_fraction = train_data.isna().mean()\n",
    "    empty_columns = empty_fraction[empty_fraction < t].index.tolist()\n",
    "    empty_col_num.append(len(empty_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(threshold, empty_col_num)\n",
    "plt.xlabel('Threshold for percentage of empty cells')\n",
    "plt.ylabel('Number of non empty columns')\n",
    "plt.title('Non Empty columns')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_dict ={}\n",
    "column_dict = dict(zip(threshold, empty_col_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fraction = train_data.isna().mean()\n",
    "less_than_40pc_columns = empty_fraction[empty_fraction <= 0.4].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fraction = train_data.isna().mean()\n",
    "less_than_20pc_columns = empty_fraction[empty_fraction <= 0.2].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fraction = train_data.isna().mean()\n",
    "less_than_11pc_columns = empty_fraction[empty_fraction <= 0.11].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(less_than_40pc_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(less_than_20pc_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(less_than_11pc_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 = train_data[less_than_11pc_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data1.to_csv('t1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2 = train_data[less_than_20pc_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_data2, target_data], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of empty cells in each row\n",
    "empty_counts = data.isna().sum(axis=1)\n",
    "\n",
    "# Calculate the fraction of empty cells in each row\n",
    "empty_fractions = empty_counts / len(data.columns)\n",
    "\n",
    "# Find the rows where 97% or more of the cells are empty - note only 4 columns are mandatory around 2.4% of 165 data points\n",
    "rows_with_mostly_empty_cells = data[empty_fractions >= 0.9]\n",
    "\n",
    "# Print the rows where 95% or more of the cells are empty\n",
    "print(rows_with_mostly_empty_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows where 97% or more of the cells are empty\n",
    "final_data = data.drop(index=rows_with_mostly_empty_cells.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fraction = final_data.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = final_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_columns = list(set(column_list) - set(target_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_data[final_train_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =final_data['Muscle fat infiltration | Instance 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# use KNN imputation to impute missing values\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# create a new dataframe with the imputed values\n",
    "X_imputed = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= y.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= y['Muscle fat infiltration | Instance 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = pd.concat([X_imputed , y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# create a correlation matrix\n",
    "corr_matrix = corr_data.corr()\n",
    "\n",
    "# plot the correlation matrix as a heatmap\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# get the top n most correlated features\n",
    "n = 10\n",
    "top_n_features = corr_matrix.nlargest(n, 'Muscle fat infiltration | Instance 2')['Muscle fat infiltration | Instance 2'].index\n",
    "top_n_corr_matrix = corr_matrix.loc[top_n_features, top_n_features]\n",
    "\n",
    "# plot the heatmap\n",
    "sns.heatmap(top_n_corr_matrix, annot=True, cmap='coolwarm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# train a random forest regressor and get feature importance scores\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# get the indices of the most important features\n",
    "sorted_idx = importances.argsort()[::-1]\n",
    "selected_features = X.columns[sorted_idx[:20]]\n",
    "#print(\"Selected features:\", selected_features)\n",
    "sf1=selected_features.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= X[sf1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import Lasso\n",
    "\n",
    "# # train a Lasso regression model and select non-zero coefficients\n",
    "# lasso = Lasso(alpha=0.1)\n",
    "# lasso.fit(X, y)\n",
    "# selected_features = X.columns[lasso.coef_ != 0]\n",
    "# #print(\"Selected features:\", selected_features)\n",
    "# sf2=selected_features.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['N1']=((X['Total tissue fat percentage | Instance 2'])-X['Total tissue fat percentage | Instance 2'].mean())/X['Total tissue fat percentage | Instance 2'].std()\n",
    "X['N2']=((X[ 'Trunk tissue fat percentage | Instance 2'])-X[ 'Trunk tissue fat percentage | Instance 2'].mean())/X[ 'Trunk tissue fat percentage | Instance 2'].std()\n",
    "X['N3']=((X[ 'L1-L4 average width | Instance 2'])-X[ 'L1-L4 average width | Instance 2'].mean())/X[ 'L1-L4 average width | Instance 2'].std()\n",
    "X['N4']=((X[ 'L1-L4 average height | Instance 2'])-X[ 'L1-L4 average height | Instance 2'].mean())/X[ 'L1-L4 average height | Instance 2'].std()\n",
    "X['N5']=((X[ 'Gynoid total mass | Instance 2'])-X[ 'Gynoid total mass | Instance 2'].mean())/X[ 'Gynoid total mass | Instance 2'].std()\n",
    "X['N6']=((X[ 'Gynoid tissue fat percentage | Instance 2'])-X[ 'Gynoid tissue fat percentage | Instance 2'].mean())/X[ 'Gynoid tissue fat percentage | Instance 2'].std()\n",
    "X['N7']=((X[ 'Arms tissue fat percentage | Instance 2'])-X[ 'Arms tissue fat percentage | Instance 2'].mean())/X[ 'Arms tissue fat percentage | Instance 2'].std()\n",
    "X['N8']=((X[ 'Head bone area | Instance 2'])-X[ 'Head bone area | Instance 2'].mean())/X[ 'Head bone area | Instance 2'].std()\n",
    "X['N9']=((X[ 'L1-L4 TBS (trabecular bone score) | Instance 2'])-X[ 'L1-L4 TBS (trabecular bone score) | Instance 2'].mean())/X[ 'L1-L4 TBS (trabecular bone score) | Instance 2'].std()\n",
    "X['N10']=((X[ 'Legs BMD (bone mineral density) | Instance 2'])-X[ 'Legs BMD (bone mineral density) | Instance 2'].mean())/X[ 'Legs BMD (bone mineral density) | Instance 2'].std()\n",
    "X['N11']=((X[ 'Legs tissue fat percentage | Instance 2'])-X[ 'Legs tissue fat percentage | Instance 2'].mean())/X[ 'Legs tissue fat percentage | Instance 2'].std()\n",
    "X['N12']=((X[ 'Android total mass | Instance 2'])-X[ 'Android total mass | Instance 2'].mean())/X[ 'Android total mass | Instance 2'].std()\n",
    "#X['N13']=((X[ 'Ribs bone area | Instance 2'])-X[ 'Ribs bone area | Instance 2'].mean())/X[ 'Ribs bone area | Instance 2'].std()\n",
    "X['N14']=((X[ 'Arms combined bone area | Instance 2'])-X[ 'Arms combined bone area | Instance 2'].mean())/X[ 'Arms combined bone area | Instance 2'].std()\n",
    "X['N15']=((X[ 'Android tissue fat percentage | Instance 2'])-X[ 'Android tissue fat percentage | Instance 2'].mean())/X[ 'Android tissue fat percentage | Instance 2'].std()\n",
    "X['N16']=((X[ 'Femur shaft bone area (right) | Instance 2'])-X[ 'Femur shaft bone area (right) | Instance 2'].mean())/X[ 'Femur shaft bone area (right) | Instance 2'].std()\n",
    "X['N17']=((X[ 'Arms total mass | Instance 2'])-X[ 'Arms total mass | Instance 2'].mean())/X[ 'Arms total mass | Instance 2'].std()\n",
    "#X['N18']=((X[ 'Ribs BMD (bone mineral density) | Instance 2'])-X[ 'Ribs BMD (bone mineral density) | Instance 2'].mean())/X[ 'Ribs BMD (bone mineral density) | Instance 2'].std()\n",
    "#X['N19']=((X[ 'Head BMD (bone mineral density) | Instance 2'])-X[ 'Head BMD (bone mineral density) | Instance 2'].mean())/X[ 'Head BMD (bone mineral density) | Instance 2'].std()\n",
    "#X['N20']=((X[ 'Spine bone area | Instance 2'])-X[ 'Spine bone area | Instance 2'].mean())/X[ 'Spine bone area | Instance 2'].std()\n",
    "\n",
    "X['L1']=np.log(X['Total tissue fat percentage | Instance 2'])\n",
    "X['L2']=np.log(X[ 'Trunk tissue fat percentage | Instance 2'])\n",
    "X['L3']=np.log(X[ 'L1-L4 average width | Instance 2'])\n",
    "X['L4']=np.log(X[ 'L1-L4 average height | Instance 2'])\n",
    "X['L5']=np.log(X[ 'Gynoid total mass | Instance 2'])\n",
    "X['L6']=np.log(X[ 'Gynoid tissue fat percentage | Instance 2'])\n",
    "X['L7']=np.log(X[ 'Arms tissue fat percentage | Instance 2'])\n",
    "X['L8']=np.log(X[ 'Head bone area | Instance 2'])\n",
    "X['L9']=np.log(X[ 'L1-L4 TBS (trabecular bone score) | Instance 2'])\n",
    "X['L10']=np.log(X[ 'Legs BMD (bone mineral density) | Instance 2'])\n",
    "X['L11']=np.log(X[ 'Legs tissue fat percentage | Instance 2'])\n",
    "X['L12']=np.log(X[ 'Android total mass | Instance 2'])\n",
    "# X['L13']=np.log(X[ 'Ribs bone area | Instance 2'])\n",
    "X['L14']=np.log(X[ 'Arms combined bone area | Instance 2'])\n",
    "X['L15']=np.log(X[ 'Android tissue fat percentage | Instance 2'])\n",
    "X['L16']=np.log(X[ 'Femur shaft bone area (right) | Instance 2'])\n",
    "X['L17']=np.log(X[ 'Arms total mass | Instance 2'])\n",
    "# X['L18']=np.log(X[ 'Ribs BMD (bone mineral density) | Instance 2'])\n",
    "#X['L19']=np.log(X[ 'Head BMD (bone mineral density) | Instance 2'])\n",
    "#X['L20']=np.log(X[ 'Spine bone area | Instance 2'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# define custom scoring function\n",
    "def auc_score(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    count = 0\n",
    "    score = 0\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if y_true[i] > y_true[j]:\n",
    "                if y_pred[i] > y_pred[j]:\n",
    "                    score += 1\n",
    "                elif y_pred[i] == y_pred[j]:\n",
    "                    score += 0.5\n",
    "                count += 1\n",
    "    return score / count if count > 0 else 0\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# define models and their hyperparameters for RandomizedSearchCV\n",
    "models = {\n",
    "    \"Linear Regression\": {\n",
    "        \"model\": LinearRegression(),\n",
    "        \"params\": {}\n",
    "    },\n",
    "    \"Random Forest Regressor\": {\n",
    "        \"model\": RandomForestRegressor(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [10],\n",
    "            \"max_depth\": [5 , 10, 15],\n",
    "            \"min_samples_split\": [ 5, 10]\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost Regressor\": {\n",
    "        \"model\": XGBRegressor(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [10],\n",
    "            \"max_depth\": [5, 10 , 15],\n",
    "            \"learning_rate\": [0.1, 0.01, 0.001]\n",
    "        }\n",
    "    },\n",
    "    \"Decision Tree Regressor\": {\n",
    "        \"model\": DecisionTreeRegressor(),\n",
    "        \"params\": {\n",
    "            \"min_samples_split\": [ 5, 10],\n",
    "            \"max_depth\": [5, 10 , 15],\n",
    "            'max_features': [10, 15]\n",
    "        }\n",
    "    },\n",
    "    \"KNN Regressor\": {\n",
    "        \"model\": KNeighborsRegressor(),\n",
    "        \"params\": {\n",
    "             'n_neighbors': [10,15]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# perform RandomizedSearchCV and evaluate models on test set\n",
    "for name, model_params in models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    model = model_params[\"model\"]\n",
    "    params = model_params[\"params\"]\n",
    "    auc_scorer = make_scorer(auc_score, greater_is_better=True)\n",
    "    regressor = RandomizedSearchCV(model, params, n_iter=5, cv=5, scoring=auc_scorer, random_state=42)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    score = auc_score(y_test, y_pred)\n",
    "    rmse_score = calculate_rmse(y_test, y_pred)\n",
    "    print(f\"  Best params: {regressor.best_params_}\")\n",
    "    print(f\"  Test AUC score: {score}\")\n",
    "    print(f\"  Test RMSE score: {rmse_score}\")\n",
    "    \n",
    "# perform RandomizedSearchCV and evaluate models on test set\n",
    "for name, model_params in models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    model = model_params[\"model\"]\n",
    "    params = model_params[\"params\"]\n",
    "    rmse_scorer = make_scorer(calculate_rmse, greater_is_better=False)\n",
    "    regressor = RandomizedSearchCV(model, params, n_iter=5, cv=5, scoring=rmse_scorer, random_state=42)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    score = auc_score(y_test, y_pred)\n",
    "    rmse_score = calculate_rmse(y_test, y_pred)\n",
    "    print(f\"  Best params: {regressor.best_params_}\")\n",
    "    print(f\"  Test AUC score: {score}\")\n",
    "    print(f\"  Test RMSE score: {rmse_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.isinf(X).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "\n",
    "def auc_score(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    count = 0\n",
    "    score = 0\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if y_true[i] > y_true[j]:\n",
    "                if y_pred[i] > y_pred[j]:\n",
    "                    score += 1\n",
    "                elif y_pred[i] == y_pred[j]:\n",
    "                    score += 0.5\n",
    "                count += 1\n",
    "    return score / count if count > 0 else 0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to tensors and move to GPU\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).cuda()\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).cuda()\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).cuda()\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1).cuda()\n",
    "\n",
    "# Create PyTorch DataLoader objects\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "    \n",
    "# Define the model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,hidden_size1, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size1)\n",
    "        self.fc3 = nn.Linear(hidden_size1, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create the model, loss function, and optimizer\n",
    "model = Net(input_size=X.shape[1], hidden_size=32, hidden_size1=8, output_size=1).cuda()\n",
    "criterion = RMSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch %d loss: %.3f' % (epoch + 1, running_loss / len(train_loader)))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "y_pred = model(X_test)\n",
    "test_loss = criterion(y_pred, y_test)\n",
    "print('Test loss: %.3f' % (test_loss.item()))\n",
    "\n",
    "# Calculate AUC score on test data\n",
    "y_pred_np = y_pred.cpu().detach().numpy().flatten()\n",
    "y_test_np = y_test.cpu().detach().numpy().flatten()\n",
    "auc_score = auc_score(y_test_np, y_pred_np)\n",
    "print('AUC score: %.3f' % auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp = ['Age at recruitment', 'Sex', 'Muscle fat infiltration | Instance 2']\n",
    "fplt = df[lp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create boxplot\n",
    "fig, ax = plt.subplots()\n",
    "ax = df.boxplot(by=['Age at recruitment'], column='Muscle fat infiltration | Instance 2', ax=ax)\n",
    "ax.set_xlabel('(Age)')\n",
    "ax.set_ylabel('MFI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create boxplot\n",
    "fig, ax = plt.subplots()\n",
    "ax = df.boxplot(by=['Sex'], column='Muscle fat infiltration | Instance 2', ax=ax)\n",
    "ax.set_xlabel('(Sex)')\n",
    "ax.set_ylabel('MFI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
